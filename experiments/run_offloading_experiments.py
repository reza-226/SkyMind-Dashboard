"""
Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ Offloading
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

import json
import numpy as np
from offloading_simulation.layers import LayerFactory
from offloading_simulation.task_generator import TaskGenerator, TaskComplexity
from offloading_simulation.metrics import OffloadingResult, MetricsCalculator
from offloading_simulation.visualizer import OffloadingVisualizer


class OffloadingExperiment:
    """Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ø²Ù…Ø§ÛŒØ´"""
    
    def __init__(self, output_dir: str = "results/offloading_results"):
        self.output_dir = Path(output_dir)
        self.layers = LayerFactory.create_all_layers()
        self.task_gen = TaskGenerator()
        self.metrics_calc = MetricsCalculator()
        
    def run_offloading(self, task, layer):
        """Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÛŒÚ© ØªØµÙ…ÛŒÙ… Offloading"""
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§
        proc_time = layer.calculate_processing_time(task.computational_load)
        trans_time = layer.calculate_transmission_time(task.data_size)
        total_latency = proc_time + trans_time + layer.base_latency
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø±Ú˜ÛŒ
        energy = layer.calculate_energy(task.computational_load)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆÙÙ‚ÛŒØª
        success = total_latency <= task.deadline
        deadline_met = success
        
        return OffloadingResult(
            task_id=task.task_id,
            layer_name=layer.name.lower(),
            success=success,
            latency=total_latency,
            energy=energy,
            deadline_met=deadline_met,
            processing_time=proc_time,
            transmission_time=trans_time
        )
    
    def run_complexity_experiment(self, complexity: TaskComplexity, num_tasks: int = 100):
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø³Ø·Ø­ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ
        """
        print(f"\n{'='*60}")
        print(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø¢Ø²Ù…Ø§ÛŒØ´: {complexity.value.upper()}")
        print(f"{'='*60}")
        
        # ØªÙˆÙ„ÛŒØ¯ Taskâ€ŒÙ‡Ø§
        tasks = [self.task_gen.generate_task(i, complexity) for i in range(num_tasks)]
        print(f"âœ… {num_tasks} Task ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯")
        
        # Ø¢Ø²Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù‡Ø± Ù„Ø§ÛŒÙ‡
        layer_results = {}
        
        for layer_name, layer in self.layers.items():
            results = []
            
            for task in tasks:
                result = self.run_offloading(task, layer)
                results.append(result)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
            scalability = self.metrics_calc.calculate_scalability(results)
            energy_metrics = self.metrics_calc.calculate_energy_efficiency(results)
            throughput = self.metrics_calc.calculate_throughput(results)
            
            avg_latency = np.mean([r.latency for r in results if r.success]) if results else 0
            
            layer_results[layer_name] = {
                "scalability": scalability,
                "energy_mean": energy_metrics["mean"],
                "energy_std": energy_metrics["std"],
                "throughput": throughput["total"],
                "avg_latency": avg_latency,
                "raw_results": [
                    {
                        "task_id": r.task_id,
                        "success": r.success,
                        "latency": r.latency,
                        "energy": r.energy
                    }
                    for r in results
                ]
            }
            
            print(f"  {layer.name:8s} | Success: {scalability:5.1f}% | "
                  f"Energy: {energy_metrics['mean']:6.2f}J | "
                  f"Latency: {avg_latency:7.2f}ms")
        
        return layer_results
    
    def save_results(self, results: dict, complexity: str):
        """Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬"""
        output_path = self.output_dir / complexity
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Ø°Ø®ÛŒØ±Ù‡ JSON
        metrics_file = output_path / "metrics.json"
        with open(metrics_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ Ù†ØªØ§ÛŒØ¬ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {metrics_file}")
    
    def run_all_experiments(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§"""
        print("\n" + "="*60)
        print("ğŸ¯ Ø´Ø±ÙˆØ¹ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ Offloading")
        print("="*60)
        
        complexities = [
            (TaskComplexity.SIMPLE, "simple"),
            (TaskComplexity.MEDIUM, "medium"),
            (TaskComplexity.COMPLEX, "complex")
        ]
        
        for complexity_enum, complexity_name in complexities:
            results = self.run_complexity_experiment(complexity_enum, num_tasks=100)
            self.save_results(results, complexity_name)
        
        print("\n" + "="*60)
        print("âœ… Ù‡Ù…Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù†Ø¯!")
        print("="*60)
        
        # ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
        print("\nğŸ¨ ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§...")
        visualizer = OffloadingVisualizer()
        visualizer.generate_all_visualizations(str(self.output_dir))


if __name__ == "__main__":
    experiment = OffloadingExperiment()
    experiment.run_all_experiments()
