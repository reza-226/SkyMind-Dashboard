import json
import pandas as pd
import numpy as np
from pathlib import Path
from scipy import stats
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import seaborn as sns

class NumpyEncoder(json.JSONEncoder):
    """JSON Encoder Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø¯Ø§Ø¯Ù‡ NumPy"""
    def default(self, obj):
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)

class StatisticalAnalyzer:
    def __init__(self, results_file='results/multi_tier_evaluation/final_results.json'):
        self.results_file = Path(results_file)
        self.output_dir = Path('results/multi_tier_evaluation/statistical_analysis')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        self.data = {
            'tier': [],
            'complexity': [],
            'latency': [],
            'energy': [],
            'success_rate': [],
            'scalability': [],
            'throughput': []
        }
        self.df = None
        
    def load_results(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†ØªØ§ÛŒØ¬ Ø§Ø² ÙØ§ÛŒÙ„ JSON"""
        with open(self.results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø±Ø§ÛŒÙ‡ results
        scenarios = data.get('results', [])
        
        for scenario_data in scenarios:
            # âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ config Ùˆ metrics
            config = scenario_data.get('config', {})
            metrics = scenario_data.get('metrics', {})
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ metrics
            if not metrics:
                print(f"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: metrics Ø¨Ø±Ø§ÛŒ {scenario_data.get('scenario_id')} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
                continue
            
            tier = scenario_data.get('tier')
            complexity = scenario_data.get('complexity')
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            self.data['tier'].append(tier)
            self.data['complexity'].append(complexity)
            self.data['latency'].append(metrics.get('latency_ms', 0))
            self.data['energy'].append(metrics.get('energy_joules', 0))
            self.data['success_rate'].append(metrics.get('success_rate', 0))
            self.data['scalability'].append(metrics.get('scalability_score', 0))
            self.data['throughput'].append(metrics.get('throughput', 0))
        
        self.df = pd.DataFrame(self.data)
        print(f"âœ… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {len(self.df)} Ø³Ù†Ø§Ø±ÛŒÙˆ\n")
        
    def descriptive_statistics(self):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ"""
        print("\n" + "="*70)
        print("ğŸ“Š Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ (Descriptive Statistics)")
        print("="*70)
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        desc = self.df.describe()
        print("\n1ï¸âƒ£ Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±ÛŒ Ú©Ù„ÛŒ:")
        print(desc.to_string())
        
        # Ø¢Ù…Ø§Ø± Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Tier
        print("\n2ï¸âƒ£ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Tier:")
        tier_stats = self.df.groupby('tier')[['latency', 'energy', 'success_rate', 'throughput']].mean()
        print(tier_stats.to_string())
        
        # Ø¢Ù…Ø§Ø± Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Complexity
        print("\n3ï¸âƒ£ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Complexity:")
        complexity_stats = self.df.groupby('complexity')[['latency', 'energy', 'success_rate', 'throughput']].mean()
        print(complexity_stats.to_string())
        
        # Ø°Ø®ÛŒØ±Ù‡
        with open(self.output_dir / 'descriptive_stats.txt', 'w', encoding='utf-8') as f:
            f.write("DESCRIPTIVE STATISTICS\n")
            f.write("="*70 + "\n\n")
            f.write("Overall Summary:\n")
            f.write(desc.to_string() + "\n\n")
            f.write("By Tier:\n")
            f.write(tier_stats.to_string() + "\n\n")
            f.write("By Complexity:\n")
            f.write(complexity_stats.to_string())
            
    def anova_analysis(self):
        """Ø¢Ù†Ø§Ù„ÛŒØ² ÙˆØ§Ø±ÛŒØ§Ù†Ø³ (ANOVA)"""
        print("\n" + "="*70)
        print("ğŸ”¬ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ø±ÛŒØ§Ù†Ø³ - ANOVA")
        print("="*70)
        
        results = {}
        metrics = ['latency', 'energy', 'success_rate', 'throughput']
        
        for metric in metrics:
            # ANOVA Ø¨Ø±Ø§ÛŒ Tier
            groups_tier = [self.df[self.df['tier'] == tier][metric].values 
                          for tier in self.df['tier'].unique()]
            f_stat_tier, p_value_tier = stats.f_oneway(*groups_tier)
            
            # ANOVA Ø¨Ø±Ø§ÛŒ Complexity
            groups_complexity = [self.df[self.df['complexity'] == comp][metric].values 
                               for comp in self.df['complexity'].unique()]
            f_stat_comp, p_value_comp = stats.f_oneway(*groups_complexity)
            
            results[metric] = {
                'tier': {'F-statistic': float(f_stat_tier), 'p-value': float(p_value_tier)},
                'complexity': {'F-statistic': float(f_stat_comp), 'p-value': float(p_value_comp)}
            }
            
            print(f"\nğŸ“Œ {metric.upper()}:")
            print(f"   Tier: F={f_stat_tier:.4f}, p={p_value_tier:.4e} {'âœ… Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±' if p_value_tier < 0.05 else 'âŒ ØºÛŒØ±Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±'}")
            print(f"   Complexity: F={f_stat_comp:.4f}, p={p_value_comp:.4e} {'âœ… Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±' if p_value_comp < 0.05 else 'âŒ ØºÛŒØ±Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±'}")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ NumpyEncoder
        with open(self.output_dir / 'anova_results.json', 'w') as f:
            json.dump(results, f, indent=2, cls=NumpyEncoder)
            
    def pairwise_ttest(self):
        """ØªØ³Øª t Ø²ÙˆØ¬ÛŒ (Pairwise T-Test) Ø¨Ø§ Cohen's d"""
        print("\n" + "="*70)
        print("ğŸ“Š ØªØ³Øª t Ø²ÙˆØ¬ÛŒ (Pairwise T-Test with Cohen's d)")
        print("="*70)
        
        tiers = self.df['tier'].unique()
        metrics = ['latency', 'energy', 'success_rate', 'throughput']
        
        results = {}
        
        for metric in metrics:
            print(f"\nğŸ”¹ {metric.upper()}:")
            results[metric] = {}
            
            for i, tier1 in enumerate(tiers):
                for tier2 in tiers[i+1:]:
                    data1 = self.df[self.df['tier'] == tier1][metric]
                    data2 = self.df[self.df['tier'] == tier2][metric]
                    
                    t_stat, p_value = stats.ttest_ind(data1, data2)
                    
                    # Cohen's d
                    pooled_std = np.sqrt((data1.std()**2 + data2.std()**2) / 2)
                    cohens_d = (data1.mean() - data2.mean()) / pooled_std if pooled_std > 0 else 0
                    
                    comparison = f"{tier1} vs {tier2}"
                    
                    # âœ… ØªØ¨Ø¯ÛŒÙ„ ØµØ±ÛŒØ­ Ø¨Ù‡ Ø§Ù†ÙˆØ§Ø¹ Ù¾Ø§ÛŒØªÙˆÙ†
                    results[metric][comparison] = {
                        't-statistic': float(t_stat),
                        'p-value': float(p_value),
                        'cohens_d': float(cohens_d),
                        'significant': bool(p_value < 0.05)  # â† Ø§ØµÙ„Ø§Ø­ Ø´Ø¯
                    }
                    
                    print(f"   {comparison}: t={t_stat:.4f}, p={p_value:.4e}, d={cohens_d:.4f} "
                          f"{'âœ… Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±' if p_value < 0.05 else 'âŒ'}")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ NumpyEncoder
        with open(self.output_dir / 'pairwise_ttest.json', 'w') as f:
            json.dump(results, f, indent=2, cls=NumpyEncoder)
            
    def correlation_analysis(self):
        """Ø¢Ù†Ø§Ù„ÛŒØ² Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ (Pearson & Spearman)"""
        print("\n" + "="*70)
        print("ğŸ”— ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ (Correlation Analysis)")
        print("="*70)
        
        metrics = ['latency', 'energy', 'success_rate', 'scalability', 'throughput']
        
        # Pearson
        pearson_corr = self.df[metrics].corr(method='pearson')
        print("\nğŸ“Œ Pearson Correlation:")
        print(pearson_corr.to_string())
        
        # Spearman
        spearman_corr = self.df[metrics].corr(method='spearman')
        print("\nğŸ“Œ Spearman Correlation:")
        print(spearman_corr.to_string())
        
        # Ù†Ù…ÙˆØ¯Ø§Ø±
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        sns.heatmap(pearson_corr, annot=True, fmt='.3f', cmap='coolwarm', ax=axes[0], vmin=-1, vmax=1)
        axes[0].set_title('Pearson Correlation')
        
        sns.heatmap(spearman_corr, annot=True, fmt='.3f', cmap='coolwarm', ax=axes[1], vmin=-1, vmax=1)
        axes[1].set_title('Spearman Correlation')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'correlation_matrix.png', dpi=300, bbox_inches='tight')
        print(f"\nğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: correlation_matrix.png")
        
        # Ø°Ø®ÛŒØ±Ù‡ CSV
        pearson_corr.to_csv(self.output_dir / 'pearson_correlation.csv')
        spearman_corr.to_csv(self.output_dir / 'spearman_correlation.csv')
        
    def regression_analysis(self):
        """Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ (Linear Regression)"""
        print("\n" + "="*70)
        print("ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† (Regression Analysis)")
        print("="*70)
        
        # Latency vs Energy
        X = self.df[['latency']].values
        y = self.df['energy'].values
        
        model = LinearRegression()
        model.fit(X, y)
        
        r2 = model.score(X, y)
        coef = model.coef_[0]
        intercept = model.intercept_
        
        print(f"\nğŸ”¹ Latency â†’ Energy:")
        print(f"   RÂ² = {r2:.4f}")
        print(f"   Ù…Ø¹Ø§Ø¯Ù„Ù‡: Energy = {coef:.6f} Ã— Latency + {intercept:.6f}")
        
        # Ù†Ù…ÙˆØ¯Ø§Ø±
        plt.figure(figsize=(10, 6))
        plt.scatter(self.df['latency'], self.df['energy'], alpha=0.6, label='Data Points')
        plt.plot(X, model.predict(X), color='red', linewidth=2, label=f'Regression Line (RÂ²={r2:.3f})')
        plt.xlabel('Latency (ms)')
        plt.ylabel('Energy (J)')
        plt.title('Regression: Latency vs Energy')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.savefig(self.output_dir / 'regression_latency_energy.png', dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: regression_latency_energy.png")
        
    def generate_report(self):
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ"""
        print("\n" + "="*70)
        print("ğŸ“„ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ")
        print("="*70)
        
        report = []
        report.append("="*70)
        report.append("STATISTICAL ANALYSIS REPORT")
        report.append("="*70)
        report.append(f"\nØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§: {len(self.df)}")
        report.append(f"Tiers: {', '.join(self.df['tier'].unique())}")
        report.append(f"Complexity Levels: {', '.join(self.df['complexity'].unique())}")
        
        report.append("\n\n1ï¸âƒ£ ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ:")
        report.append(f"   â€¢ Ø¨Ù‡ØªØ±ÛŒÙ† Tier Ø§Ø² Ù†Ø¸Ø± Latency: {self.df.groupby('tier')['latency'].mean().idxmin()}")
        report.append(f"   â€¢ Ø¨Ù‡ØªØ±ÛŒÙ† Tier Ø§Ø² Ù†Ø¸Ø± Energy: {self.df.groupby('tier')['energy'].mean().idxmin()}")
        report.append(f"   â€¢ Ø¨Ù‡ØªØ±ÛŒÙ† Tier Ø§Ø² Ù†Ø¸Ø± Success Rate: {self.df.groupby('tier')['success_rate'].mean().idxmax()}")
        
        report_text = "\n".join(report)
        print(report_text)
        
        with open(self.output_dir / 'final_report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)
            
        print(f"\nâœ… Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {self.output_dir / 'final_report.txt'}")
        
    def run_all_analyses(self):
        """Ø§Ø¬Ø±Ø§ÛŒ ØªÙ…Ø§Ù… ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§"""
        print("\n" + "="*70)
        print("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ Ø¬Ø§Ù…Ø¹")
        print("="*70)
        
        self.load_results()
        self.descriptive_statistics()
        self.anova_analysis()
        self.pairwise_ttest()
        self.correlation_analysis()
        self.regression_analysis()
        self.generate_report()
        
        print("\n" + "="*70)
        print("âœ… ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
        print(f"ğŸ“‚ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ: {self.output_dir}")
        print("="*70)

if __name__ == "__main__":
    analyzer = StatisticalAnalyzer()
    analyzer.run_all_analyses()
