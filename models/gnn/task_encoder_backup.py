"""
GNN-based Task Encoder for DAG Processing
Ø±Ù…Ø²Ú¯Ø°Ø§Ø± GNN Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Task DAG
"""

import torch
import torch.nn as nn
from torch_geometric.data import Data
from typing import Tuple, Optional
from .attention_layers import MultiHeadGATLayer


class GNNTaskEncoder(nn.Module):
    """
    Ø±Ù…Ø²Ú¯Ø°Ø§Ø± GNN Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ embeddings Ø§Ø² Task DAG
    
    Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø§Ø² Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Graph Attention Network Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
    Ù†Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ù‡Ø§Ù† tasks Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ critical path Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    
    def __init__(
        self,
        node_feature_dim: int = 9,
        edge_feature_dim: int = 3,
        hidden_dim: int = 256,
        embedding_dim: int = 256,
        num_gat_layers: int = 3,
        num_heads: int = 4,
        dropout: float = 0.1
    ):
        """
        Args:
            node_feature_dim: Ø¨Ø¹Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ù‡ (task features)
            edge_feature_dim: Ø¨Ø¹Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ù„ (dependency features)
            hidden_dim: Ø¨Ø¹Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ÙÛŒ
            embedding_dim: Ø¨Ø¹Ø¯ embedding Ù†Ù‡Ø§ÛŒÛŒ
            num_gat_layers: ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ GAT
            num_heads: ØªØ¹Ø¯Ø§Ø¯ attention heads
            dropout: Ù†Ø±Ø® dropout
        """
        super().__init__()
        
        self.node_feature_dim = node_feature_dim
        self.edge_feature_dim = edge_feature_dim
        self.hidden_dim = hidden_dim
        self.embedding_dim = embedding_dim
        self.num_gat_layers = num_gat_layers
        
        # Ù„Ø§ÛŒÙ‡ ÙˆØ±ÙˆØ¯ÛŒ: ØªØ¨Ø¯ÛŒÙ„ node features Ø¨Ù‡ hidden dimension
        self.input_projection = nn.Sequential(
            nn.Linear(node_feature_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ELU(),
            nn.Dropout(dropout)
        )
        
        # Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ GAT
        self.gat_layers = nn.ModuleList()
        for i in range(num_gat_layers):
            self.gat_layers.append(
                MultiHeadGATLayer(
                    in_channels=hidden_dim,
                    out_channels=hidden_dim,
                    heads=num_heads,
                    edge_dim=edge_feature_dim,
                    dropout=dropout,
                    residual=True
                )
            )
        
        # Ù„Ø§ÛŒÙ‡ Ø®Ø±ÙˆØ¬ÛŒ: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ embedding dimension
        self.output_projection = nn.Sequential(
            nn.Linear(hidden_dim, embedding_dim),
            nn.LayerNorm(embedding_dim),
            nn.ELU()
        )
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ critical path scores
        self.critical_path_head = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim // 2),
            nn.ELU(),
            nn.Dropout(dropout),
            nn.Linear(embedding_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # Global pooling Ø¨Ø±Ø§ÛŒ graph-level representation
        self.global_pool = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim),
            nn.ELU()
        )
    
    def forward(
        self,
        task_graph: Data,
        return_attention: bool = False
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass
        
        Args:
            task_graph: PyTorch Geometric Data object Ø­Ø§ÙˆÛŒ:
                - x: node features [num_nodes, node_feature_dim]
                - edge_index: edge indices [2, num_edges]
                - edge_attr: edge features [num_edges, edge_feature_dim]
            return_attention: Ø§Ú¯Ø± True Ø¨Ø§Ø´Ø¯ØŒ attention weights Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        
        Returns:
            task_embeddings: embeddings Ù‡Ø± task [num_nodes, embedding_dim]
            critical_scores: Ø§Ù…ØªÛŒØ§Ø² critical path Ù‡Ø± task [num_nodes, 1]
        """
        x = task_graph.x
        edge_index = task_graph.edge_index
        edge_attr = task_graph.edge_attr
        
        # Input projection
        x = self.input_projection(x)
        
        # GAT layers
        attention_weights = []
        for gat_layer in self.gat_layers:
            x = gat_layer(x, edge_index, edge_attr)
            
            # Ø°Ø®ÛŒØ±Ù‡ attention weights Ø¨Ø±Ø§ÛŒ visualization (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
            if return_attention:
                # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ attention weights Ø±Ø§ Ø§Ø² Ù„Ø§ÛŒÙ‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯
                pass
        
        # Output projection
        task_embeddings = self.output_projection(x)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ critical path scores
        critical_scores = self.critical_path_head(task_embeddings)
        
        if return_attention:
            return task_embeddings, critical_scores, attention_weights
        
        return task_embeddings, critical_scores
    
    def get_graph_embedding(self, task_graph: Data) -> torch.Tensor:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ embedding Ú©Ù„ Ú¯Ø±Ø§Ù (Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§)
        
        Args:
            task_graph: Ú¯Ø±Ø§Ù task
        
        Returns:
            graph_embedding: embedding Ú©Ù„ Ú¯Ø±Ø§Ù [embedding_dim]
        """
        task_embeddings, _ = self.forward(task_graph)
        
        # Global mean pooling
        graph_embedding = torch.mean(task_embeddings, dim=0)
        
        # Ø§Ø¹Ù…Ø§Ù„ transformation
        graph_embedding = self.global_pool(graph_embedding)
        
        return graph_embedding
    
    def get_critical_path(
        self,
        task_graph: Data,
        threshold: float = 0.5
    ) -> torch.Tensor:
        """
        Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ tasks Ø¯Ø± critical path
        
        Args:
            task_graph: Ú¯Ø±Ø§Ù task
            threshold: Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ critical task
        
        Returns:
            critical_mask: Ù…Ø§Ø³Ú© boolean Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ critical tasks [num_nodes]
        """
        _, critical_scores = self.forward(task_graph)
        critical_mask = (critical_scores.squeeze() > threshold)
        return critical_mask
    
    def count_parameters(self) -> int:
        """Ø´Ù…Ø§Ø±Ø´ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¢Ù…ÙˆØ²Ø´"""
        return sum(p.numel() for p in self.parameters() if p.requires_grad)


# ========================================
# Utility Functions
# ========================================

def create_task_graph_data(
    node_features: torch.Tensor,
    edge_index: torch.Tensor,
    edge_features: Optional[torch.Tensor] = None
) -> Data:
    """
    Ø§ÛŒØ¬Ø§Ø¯ PyTorch Geometric Data object Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ task
    
    Args:
        node_features: ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ tasks [num_nodes, node_feature_dim]
        edge_index: indices ÛŒØ§Ù„â€ŒÙ‡Ø§ÛŒ DAG [2, num_edges]
        edge_features: ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ dependencies [num_edges, edge_feature_dim]
    
    Returns:
        data: PyTorch Geometric Data object
    """
    data = Data(
        x=node_features,
        edge_index=edge_index,
        edge_attr=edge_features
    )
    return data


def visualize_critical_path(
    task_graph: Data,
    critical_scores: torch.Tensor,
    task_ids: Optional[list] = None
):
    """
    Ù†Ù…Ø§ÛŒØ´ critical path (Ø¨Ø±Ø§ÛŒ debugging)
    
    Args:
        task_graph: Ú¯Ø±Ø§Ù task
        critical_scores: Ø§Ù…ØªÛŒØ§Ø²Ø§Øª critical path
        task_ids: Ù„ÛŒØ³Øª Ø´Ù†Ø§Ø³Ù‡ tasks (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    """
    if task_ids is None:
        task_ids = list(range(task_graph.num_nodes))
    
    print("\n" + "="*50)
    print("ðŸŽ¯ Critical Path Analysis")
    print("="*50)
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ tasks Ø¨Ø± Ø§Ø³Ø§Ø³ critical score
    scores = critical_scores.squeeze().detach().cpu().numpy()
    sorted_indices = scores.argsort()[::-1]
    
    for idx in sorted_indices:
        task_id = task_ids[idx]
        score = scores[idx]
        status = "ðŸ”´ CRITICAL" if score > 0.5 else "âšª Normal"
        print(f"Task {task_id}: {score:.4f} {status}")
    
    print("="*50 + "\n")
