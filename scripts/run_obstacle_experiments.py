"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ§ª Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¬Ø§Ù…Ø¹ Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ÙˆØ§Ù†Ø¹
Ù…Ø³ÛŒØ±: scripts/run_obstacle_experiments.py (NEW)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
from tqdm import tqdm
import json
from datetime import datetime
from typing import Dict, List
import argparse

from core.env_multi import MultiUAVEnvironment
from agents.agent_maddpg_multi import MADDPG_Agent
from agents.dqn import DQNAgent
from agents.bls import BLSAgent
from agents.ga import GAAgent
from agents.ecori import ECORIAgent
from analysis.realtime.obstacle_comparison import ObstacleComparison


class ObstacleExperimentRunner:
    """
    Ø§Ø¬Ø±Ø§ÛŒ Ú©Ù†Ù†Ø¯Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ÙˆØ§Ù†Ø¹
    """
    
    def __init__(self,
                 n_episodes: int = 100,
                 max_steps: int = 500,
                 n_runs: int = 5,
                 save_dir: str = 'results/obstacle_experiments'):
        """
        Args:
            n_episodes: ØªØ¹Ø¯Ø§Ø¯ Ø§Ù¾ÛŒØ²ÙˆØ¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¢Ø²Ù…Ø§ÛŒØ´
            max_steps: Ø­Ø¯Ø§Ú©Ø«Ø± Ú¯Ø§Ù… Ø¯Ø± Ù‡Ø± Ø§Ù¾ÛŒØ²ÙˆØ¯
            n_runs: ØªØ¹Ø¯Ø§Ø¯ Ø§Ø¬Ø±Ø§Ù‡Ø§ÛŒ Ù…Ø³ØªÙ‚Ù„ (Ø¨Ø±Ø§ÛŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ)
            save_dir: Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
        """
        self.n_episodes = n_episodes
        self.max_steps = max_steps
        self.n_runs = n_runs
        self.save_dir = save_dir
        
        os.makedirs(save_dir, exist_ok=True)
        
        self.complexities = ['simple', 'medium', 'complex']
        self.algorithms = ['MADDPG', 'DQN', 'BLS', 'GA', 'ECORI']
        self.layers = ['Ground', 'Local', 'Edge', 'Cloud']
        
        self.comparison = ObstacleComparison()
        
        print("â”" * 70)
        print("ðŸ§ª Obstacle Experiment Runner Initialized")
        print(f"   Episodes: {n_episodes}")
        print(f"   Max Steps: {max_steps}")
        print(f"   Runs: {n_runs}")
        print(f"   Complexities: {self.complexities}")
        print(f"   Algorithms: {self.algorithms}")
        print("â”" * 70)
    
    def create_agent(self, 
                     algorithm: str, 
                     env: MultiUAVEnvironment,
                     layer: str) -> object:
        """
        Ø§ÛŒØ¬Ø§Ø¯ agent Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…
        """
        obs_dim = env.observation_space.shape[0]
        act_dim = env.action_space.shape[0]
        
        if algorithm == 'MADDPG':
            return MADDPGAgent(
                n_agents=env.n_uavs,
                obs_dim=obs_dim,
                act_dim=act_dim,
                hidden_dim=256,
                lr_actor=1e-4,
                lr_critic=1e-3,
                gamma=0.99,
                tau=0.01
            )
        elif algorithm == 'DQN':
            return DQNAgent(
                state_dim=obs_dim,
                action_dim=act_dim,
                hidden_dim=128,
                lr=1e-3,
                gamma=0.99,
                epsilon_start=1.0,
                epsilon_end=0.01,
                epsilon_decay=0.995
            )
        elif algorithm == 'BLS':
            return BLSAgent(
                obs_dim=obs_dim,
                act_dim=act_dim,
                n_nodes=1000,
                n_features=200
            )
        elif algorithm == 'GA':
            return GAAgent(
                obs_dim=obs_dim,
                act_dim=act_dim,
                population_size=50,
                mutation_rate=0.1,
                crossover_rate=0.7
            )
        elif algorithm == 'ECORI':
            return ECORIAgent(
                obs_dim=obs_dim,
                act_dim=act_dim,
                hidden_dim=256,
                lr=1e-3
            )
        else:
            raise ValueError(f"Unknown algorithm: {algorithm}")
    
    def run_single_experiment(self,
                             complexity: str,
                             algorithm: str,
                             layer: str,
                             run_id: int,
                             seed: int) -> Dict:
        """
        Ø§Ø¬Ø±Ø§ÛŒ ÛŒÚ© Ø¢Ø²Ù…Ø§ÛŒØ´ ÙˆØ§Ø­Ø¯
        
        Returns:
            dict Ø¨Ø§ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
        """
        # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ÛŒØ·
        env = MultiUAVEnvironment(
            n_uavs=3,
            n_users=10,
            obstacle_complexity=complexity,
            enable_obstacles=True,
            seed=seed
        )
        
        # Ø§ÛŒØ¬Ø§Ø¯ agent
        agent = self.create_agent(algorithm, env, layer)
        
        # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ
        episode_rewards = []
        episode_delays = []
        episode_energies = []
        episode_collisions = []
        episode_success = []
        
        # Ø­Ù„Ù‚Ù‡ Ø¢Ù…ÙˆØ²Ø´
        pbar = tqdm(range(self.n_episodes), 
                   desc=f"{complexity}-{algorithm}-{layer}-Run{run_id}",
                   leave=False)
        
        for episode in pbar:
            obs, info = env.reset(seed=seed + episode)
            episode_reward = 0
            done = False
            step = 0
            
            while not done and step < self.max_steps:
                # Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù‚Ø¯Ø§Ù…
                if algorithm == 'MADDPG':
                    actions = {}
                    for agent_id in range(env.n_uavs):
                        action = agent.select_action(obs[agent_id], agent_id)
                        actions[agent_id] = action
                else:
                    # Ø³Ø§ÛŒØ± Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ (ÙØ±Ø¶: single agent)
                    action = agent.select_action(obs[0])
                    actions = {i: action for i in range(env.n_uavs)}
                
                # Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø§Ù…
                next_obs, rewards, done, truncated, info = env.step(actions)
                
                # Ø°Ø®ÛŒØ±Ù‡ ØªØ¬Ø±Ø¨Ù‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
                if algorithm in ['MADDPG', 'DQN']:
                    for agent_id in range(env.n_uavs):
                        agent.store_transition(
                            obs[agent_id],
                            actions[agent_id],
                            rewards[agent_id],
                            next_obs[agent_id],
                            done
                        )
                
                episode_reward += sum(rewards.values())
                obs = next_obs
                step += 1
            
            # Ø¢Ù…ÙˆØ²Ø´ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
            if algorithm in ['MADDPG', 'DQN'] and episode % 10 == 0:
                agent.train()
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
            metrics = env.get_metrics()
            
            episode_rewards.append(episode_reward)
            episode_delays.append(metrics.get('avg_delay', 0))
            episode_energies.append(metrics.get('avg_energy', 0))
            episode_collisions.append(metrics.get('collision_rate', 0) * 100)
            episode_success.append(metrics.get('safety_rate', 0) * 100)
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ progress bar
            pbar.set_postfix({
                'Reward': f"{episode_reward:.2f}",
                'Collision': f"{episode_collisions[-1]:.1f}%"
            })
        
        pbar.close()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† (10 Ø§Ù¾ÛŒØ²ÙˆØ¯ Ø¢Ø®Ø±)
        last_n = 10
        
        return {
            'avg_delay': np.mean(episode_delays[-last_n:]),
            'avg_energy': np.mean(episode_energies[-last_n:]),
            'avg_reward': np.mean(episode_rewards[-last_n:]),
            'collision_rate': np.mean(episode_collisions[-last_n:]),
            'success_rate': np.mean(episode_success[-last_n:]),
            'path_length': 0,  # TODO: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø² env
            'computation_time': 0,  # TODO: Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø²Ù…Ø§Ù†
            'safety_score': 100 - np.mean(episode_collisions[-last_n:])
        }
    
    def run_all_experiments(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ ØªÙ…Ø§Ù… ØªØ±Ú©ÛŒØ¨Ø§Øª Ø¢Ø²Ù…Ø§ÛŒØ´
        """
        total_experiments = (
            len(self.complexities) * 
            len(self.algorithms) * 
            len(self.layers) * 
            self.n_runs
        )
        
        print(f"\nðŸš€ Starting {total_experiments} experiments...")
        print("â”" * 70)
        
        experiment_id = 0
        start_time = datetime.now()
        
        for complexity in self.complexities:
            print(f"\n{'='*70}")
            print(f"ðŸ“Š Complexity Level: {complexity.upper()}")
            print(f"{'='*70}")
            
            for algorithm in self.algorithms:
                print(f"\n  ðŸ¤– Algorithm: {algorithm}")
                
                for layer in self.layers:
                    print(f"    ðŸ“ Layer: {layer}")
                    
                    # Ø§Ø¬Ø±Ø§ÛŒ Ú†Ù†Ø¯ run Ø¨Ø±Ø§ÛŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ
                    run_results = []
                    
                    for run_id in range(self.n_runs):
                        seed = 42 + experiment_id
                        
                        try:
                            result = self.run_single_experiment(
                                complexity=complexity,
                                algorithm=algorithm,
                                layer=layer,
                                run_id=run_id,
                                seed=seed
                            )
                            run_results.append(result)
                            
                            print(f"      âœ… Run {run_id+1}/{self.n_runs} completed")
                            
                        except Exception as e:
                            print(f"      âŒ Run {run_id+1} failed: {str(e)}")
                            continue
                        
                        experiment_id += 1
                    
                    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ Ù†ØªØ§ÛŒØ¬
                    if run_results:
                        avg_result = {
                            key: np.mean([r[key] for r in run_results])
                            for key in run_results[0].keys()
                        }
                        
                        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ comparison
                        self.comparison.add_result(
                            complexity=complexity,
                            algorithm=algorithm,
                            layer=layer,
                            metrics=avg_result
                        )
                        
                        print(f"      ðŸ“ˆ Avg Results: "
                              f"Delay={avg_result['avg_delay']:.2f}ms, "
                              f"Collision={avg_result['collision_rate']:.1f}%")
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print("\n" + "â”" * 70)
        print(f"âœ… All experiments completed!")
        print(f"â±ï¸  Total time: {duration/60:.1f} minutes")
        print("â”" * 70)
    
    def generate_reports(self):
        """
        ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
        """
        print("\nðŸŽ¨ Generating reports...")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø®Ø§Ù…
        self.comparison.save_results(
            filename='obstacle_comparison_results.json'
        )
        print("  âœ… Raw results saved")
        
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        try:
            # 1. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ø§Ø®Ù„ÛŒ
            for complexity in self.complexities:
                df = self.comparison.generate_intra_complexity_comparison(complexity)
                print(f"  âœ… Intra-complexity analysis: {complexity}")
            
            # 2. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨ÛŒÙ†â€ŒÙ„Ø§ÛŒÙ‡â€ŒØ§ÛŒ
            for algo in ['MADDPG', 'DQN']:
                for complexity in ['simple', 'complex']:
                    df = self.comparison.generate_inter_layer_comparison(complexity, algo)
                    print(f"  âœ… Inter-layer analysis: {algo} ({complexity})")
            
            # 3. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ØªÙ‚Ø§Ø·Ø¹
            for algo in ['MADDPG', 'BLS']:
                for layer in ['Edge', 'Cloud']:
                    df = self.comparison.generate_cross_complexity_comparison(algo, layer)
                    print(f"  âœ… Cross-complexity analysis: {algo} on {layer}")
            
            # 4. Heatmap
            self.comparison.generate_heatmap_comparison()
            print("  âœ… Heatmap generated")
            
            # 5. Ø¬Ø¯ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡
            summary_df = self.comparison.generate_summary_table()
            print("  âœ… Summary table generated")
            
            print("\nðŸ“ All reports saved to: results/")
            
        except Exception as e:
            print(f"  âŒ Error generating reports: {str(e)}")
    
    def save_metadata(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ø²Ù…Ø§ÛŒØ´"""
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'n_episodes': self.n_episodes,
            'max_steps': self.max_steps,
            'n_runs': self.n_runs,
            'complexities': self.complexities,
            'algorithms': self.algorithms,
            'layers': self.layers,
            'total_experiments': (
                len(self.complexities) * 
                len(self.algorithms) * 
                len(self.layers) * 
                self.n_runs
            )
        }
        
        with open(f'{self.save_dir}/experiment_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"  âœ… Metadata saved")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ðŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def main():
    parser = argparse.ArgumentParser(
        description='ðŸ§ª SkyMind Obstacle Comparison Experiments'
    )
    parser.add_argument('--episodes', type=int, default=100,
                       help='Number of episodes per experiment')
    parser.add_argument('--steps', type=int, default=500,
                       help='Max steps per episode')
    parser.add_argument('--runs', type=int, default=5,
                       help='Number of independent runs')
    parser.add_argument('--quick', action='store_true',
                       help='Quick test mode (10 episodes, 1 run)')
    
    args = parser.parse_args()
    
    if args.quick:
        print("âš¡ Quick test mode enabled")
        args.episodes = 10
        args.runs = 1
    
    # Ø§ÛŒØ¬Ø§Ø¯ runner
    runner = ObstacleExperimentRunner(
        n_episodes=args.episodes,
        max_steps=args.steps,
        n_runs=args.runs
    )
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§
    runner.run_all_experiments()
    
    # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§
    runner.generate_reports()
    
    # Ø°Ø®ÛŒØ±Ù‡ metadata
    runner.save_metadata()
    
    print("\n" + "ðŸŽ‰" * 35)
    print("All done! Check results/ directory for outputs.")
    print("ðŸŽ‰" * 35)


if __name__ == "__main__":
    main()
