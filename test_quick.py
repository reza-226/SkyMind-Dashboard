# test_quick.py
import torch
import numpy as np
from agents.agent_maddpg_multi import MADDPG_Agent

# Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
state_dim = 18
action_dim = 4
n_agents = 3

print("ğŸ”§ Creating MADDPG Agent...")

# Ø§ÛŒØ¬Ø§Ø¯ agent
agent = MADDPG_Agent(
    state_dim=state_dim,
    action_dim=action_dim,
    n_agents=n_agents,
    lr=1e-3,
    gamma=0.95
)

print("âœ… Agent created successfully!")
print(f"   - State dim: {agent.state_dim}")
print(f"   - Action dim: {agent.action_dim}")
print(f"   - N agents: {agent.n_agents}")

# ØªØ³Øª act (Ø¨Ø¯ÙˆÙ† noise)
print("\nğŸ¯ Testing act() method (noise_scale=0.0)...")
state = np.random.randn(state_dim)
action = agent.act(state, noise_scale=0.0)

print(f"âœ… State shape: {state.shape}")
print(f"âœ… Action shape: {action.shape}")
print(f"âœ… Action range: [{action.min():.3f}, {action.max():.3f}]")

# ØªØ³Øª act (Ø¨Ø§ noise)
print("\nğŸ¯ Testing act() method (noise_scale=0.1)...")
action_noisy = agent.act(state, noise_scale=0.1)

print(f"âœ… Action with noise shape: {action_noisy.shape}")
print(f"âœ… Action with noise range: [{action_noisy.min():.3f}, {action_noisy.max():.3f}]")

# ØªØ³Øª Ø§ÛŒÙ†Ú©Ù‡ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ target ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯
print("\nğŸ” Checking target networks...")
print(f"âœ… Target Actor exists: {hasattr(agent, 'target_actor')}")
print(f"âœ… Target Critic exists: {hasattr(agent, 'target_critic')}")

print("\nğŸ‰ All tests passed! Agent is ready for training!")
